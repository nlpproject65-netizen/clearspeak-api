{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJ++5M01sy5LpxzwF88vMS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "795f6c08bef34a4fa71dc094d4356dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5702c973b0f7462b915fdf19b9a17e94",
              "IPY_MODEL_54cdc8c53aae4b348c636e4e2ca26c72",
              "IPY_MODEL_67465d6045654aa6890f1db26494808f"
            ],
            "layout": "IPY_MODEL_7ecfded03e2e46c487cc84a67f37a464"
          }
        },
        "5702c973b0f7462b915fdf19b9a17e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90e414b281204aa09d04abc002f7d3cb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_53b0751d4b3940f18266f1875839c22a",
            "value": "Map:‚Äá100%"
          }
        },
        "54cdc8c53aae4b348c636e4e2ca26c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a7c52e4da4a493c82dfea01552ff63e",
            "max": 260,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2564daa86bc54d6cb581532815f8a8ae",
            "value": 260
          }
        },
        "67465d6045654aa6890f1db26494808f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07b3e38681ce4f23aa9b7f1c8ee91fa2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fd62dba2c0494b83a40fd33bc678e8f0",
            "value": "‚Äá260/260‚Äá[00:00&lt;00:00,‚Äá1023.50‚Äáexamples/s]"
          }
        },
        "7ecfded03e2e46c487cc84a67f37a464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90e414b281204aa09d04abc002f7d3cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b0751d4b3940f18266f1875839c22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a7c52e4da4a493c82dfea01552ff63e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2564daa86bc54d6cb581532815f8a8ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07b3e38681ce4f23aa9b7f1c8ee91fa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd62dba2c0494b83a40fd33bc678e8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdefe582e47f4b7fbd8a6b40fa28bbf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64cef50fe0c0417b87968efe23302f9d",
              "IPY_MODEL_18d35dd056da4fd69409d77022430ec7",
              "IPY_MODEL_c80cd7bd268d4f4d800cadb4985f9fcd"
            ],
            "layout": "IPY_MODEL_b5ad779700fb44f1a071c18a35894b62"
          }
        },
        "64cef50fe0c0417b87968efe23302f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03531399141c4636a5d8d02507dc5e4e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_992b95a234bb489591cca37fad16301e",
            "value": "Map:‚Äá100%"
          }
        },
        "18d35dd056da4fd69409d77022430ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fff4f8ecd5ce421e9fb77f5c72ca52ce",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_192c3bb534184a779ae6d497d5f555aa",
            "value": 32
          }
        },
        "c80cd7bd268d4f4d800cadb4985f9fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b80c1129a4104521b86fec4cbf605e62",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a632c076f5ea45158d4974f680357ef1",
            "value": "‚Äá32/32‚Äá[00:00&lt;00:00,‚Äá640.25‚Äáexamples/s]"
          }
        },
        "b5ad779700fb44f1a071c18a35894b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03531399141c4636a5d8d02507dc5e4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "992b95a234bb489591cca37fad16301e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fff4f8ecd5ce421e9fb77f5c72ca52ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "192c3bb534184a779ae6d497d5f555aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b80c1129a4104521b86fec4cbf605e62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a632c076f5ea45158d4974f680357ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nlpproject65-netizen/clearspeak-api/blob/main/CLEARSPEAK_Days13_16_Training_FIXED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# DAYS 13-16: T5 TRANSFORMER MODEL TRAINING (FULLY FIXED)\n",
        "# Phase 3: Deep Learning Training with Continuity\n",
        "# Notebook: 06_t5_model_training_days13_16_FIXED.ipynb\n",
        "# FIX: Removed batched=True tokenization (was causing error)\n",
        "# ====================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"DAYS 13-16: T5 TRANSFORMER MODEL TRAINING (FULLY FIXED)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ========================================\n",
        "# CELL 1: ENVIRONMENT SETUP & GPU CHECK\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 1: ENVIRONMENT SETUP & GPU INITIALIZATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/ClearSpeak\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "import gc\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Clear GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(f\"\\n‚úÖ Environment ready\")\n",
        "print(f\"   üìÅ Base: {BASE}\")\n",
        "print(f\"   üî• CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 2: LOAD PHASE 1 DATA\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 2: LOAD DATA FROM PHASE 1\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    train_df = pd.read_csv(f\"{BASE}/data/processed/train.csv\")\n",
        "    val_df = pd.read_csv(f\"{BASE}/data/processed/val.csv\")\n",
        "    test_df = pd.read_csv(f\"{BASE}/data/processed/test.csv\")\n",
        "\n",
        "    print(f\"‚úÖ Data loaded:\")\n",
        "    print(f\"   Train: {len(train_df)}\")\n",
        "    print(f\"   Val:   {len(val_df)}\")\n",
        "    print(f\"   Test:  {len(test_df)}\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"   Make sure you ran Phase 1 (Days 2-7)\")\n",
        "    raise\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 3: INSTALL LIBRARIES\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 3: INSTALL REQUIRED LIBRARIES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "import subprocess\n",
        "print(\"üì¶ Installing...\")\n",
        "subprocess.check_call([\"pip\", \"install\", \"-q\",\n",
        "                      \"transformers==4.35.2\",\n",
        "                      \"datasets==2.14.5\",\n",
        "                      \"accelerate==0.24.1\", # Reverted accelerate version to match known working config\n",
        "                      \"peft==0.5.0\",        # Explicitly install peft\n",
        "                      \"bitsandbytes\",\n",
        "                      \"nltk\"])\n",
        "print(\"‚úÖ Libraries installed!\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 4: PREPARE DATA FOR TRAINING\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 4: PREPARE DATASETS FOR TRAINING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Use full dataset\n",
        "train_df_use = train_df.copy()\n",
        "val_df_use = val_df.copy()\n",
        "\n",
        "# Add T5 prefix if needed\n",
        "if not train_df_use['input_text'].iloc[0].startswith('simplify:'):\n",
        "    print(\"üîß Adding 'simplify:' prefix...\")\n",
        "    train_df_use['input_text'] = 'simplify: ' + train_df_use['input_text'].astype(str)\n",
        "    val_df_use['input_text'] = 'simplify: ' + val_df_use['input_text'].astype(str)\n",
        "    print(\"‚úÖ Prefix added!\")\n",
        "\n",
        "print(f\"‚úÖ Data prepared:\")\n",
        "print(f\"   Train: {len(train_df_use)} examples\")\n",
        "print(f\"   Val:   {len(val_df_use)} examples\")\n",
        "\n",
        "# Convert to HuggingFace Datasets\n",
        "print(\"üîÑ Converting to HuggingFace Dataset...\")\n",
        "train_dataset = Dataset.from_pandas(train_df_use[['input_text', 'target_text']])\n",
        "val_dataset = Dataset.from_pandas(val_df_use[['input_text', 'target_text']])\n",
        "print(f\"‚úÖ Datasets created!\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 5: LOAD T5 MODEL & TOKENIZER\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 5: LOAD T5 MODEL & TOKENIZER\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "model_name = \"t5-small\"\n",
        "print(f\"üì• Loading {model_name}...\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "print(f\"‚úÖ Model loaded!\")\n",
        "print(f\"   Parameters: {sum(p.numel() for p in model.parameters())/1e6:.1f}M\")\n",
        "print(f\"   Tokenizer vocab: {len(tokenizer):,}\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 6: TOKENIZE DATASETS (FIXED!) ##############################################\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 6: TOKENIZE DATASETS (FIXED - UNBATCHED)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "MAX_INPUT_LENGTH = 128\n",
        "MAX_TARGET_LENGTH = 64\n",
        "\n",
        "print(\"üîÑ Tokenizing train data...\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"\n",
        "    Tokenize input and target for a single example.\n",
        "    Padding is handled by DataCollatorForSeq2Seq.\n",
        "    \"\"\"\n",
        "    # 'examples' here refers to a single row (dictionary) from the dataset\n",
        "    # because Dataset.map is called without `batched=True` (default behavior).\n",
        "    # The previous logic of converting to a list `[input_texts]` was causing\n",
        "    # excessive nesting when combined with the tokenizer's output for lists.\n",
        "\n",
        "    input_text = examples['input_text']\n",
        "    target_text = examples['target_text']\n",
        "\n",
        "    # Tokenize inputs without padding; padding will be handled by DataCollatorForSeq2Seq\n",
        "    model_inputs = tokenizer(\n",
        "        input_text,  # Pass single string directly\n",
        "        max_length=MAX_INPUT_LENGTH,\n",
        "        truncation=True,\n",
        "        # padding=False # Explicitly set to False if needed, but omitting is default for 'do_not_pad'\n",
        "    )\n",
        "\n",
        "    # Tokenize targets without padding\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            target_text, # Pass single string directly\n",
        "            max_length=MAX_TARGET_LENGTH,\n",
        "            truncation=True,\n",
        "            # padding=False\n",
        "        )\n",
        "\n",
        "    # The tokenizer returns 'input_ids' as a list of integers for a single string input.\n",
        "    # So model_inputs['input_ids'] will be [int, int, ...]\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Tokenize all datasets (UNBATCHED - no batched=True). Each call to tokenize_function\n",
        "# processes a single example, ensuring input_ids are flat lists.\n",
        "print(\"‚è≥ Processing train dataset (this takes ~2 minutes)...\")\n",
        "tokenized_train = train_dataset.map(tokenize_function, remove_columns=['input_text', 'target_text'])\n",
        "\n",
        "print(\"‚è≥ Processing validation dataset...\")\n",
        "tokenized_val = val_dataset.map(tokenize_function, remove_columns=['input_text', 'target_text'])\n",
        "\n",
        "print(f\"‚úÖ Tokenization complete!\")\n",
        "print(f\"   Train: {len(tokenized_train)} examples\")\n",
        "print(f\"   Val:   {len(tokenized_val)} examples\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 7: DATA COLLATOR & METRICS\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 7: DATA COLLATOR & EVALUATION METRICS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "# Data collator for batching\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    padding=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "# BLEU metric calculation\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Calculate BLEU score\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # Replace -100 with pad token\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    try:\n",
        "        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    except:\n",
        "        return {\"bleu\": 0.0}\n",
        "\n",
        "    bleu_scores = []\n",
        "    for ref, pred in zip(decoded_labels, decoded_preds):\n",
        "        reference = [ref.lower().split()]\n",
        "        hypothesis = pred.lower().split()\n",
        "\n",
        "        if len(hypothesis) > 0 and len(reference[0]) > 0:\n",
        "            try:\n",
        "                score = sentence_bleu(reference, hypothesis)\n",
        "                bleu_scores.append(score)\n",
        "            except:\n",
        "                bleu_scores.append(0)\n",
        "\n",
        "    return {\"bleu\": float(np.mean(bleu_scores)) if bleu_scores else 0.0}\n",
        "\n",
        "print(\"‚úÖ Data collator & metrics configured\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 8: TRAINING ARGUMENTS (GPU-OPTIMIZED)\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 8: TRAINING CONFIGURATION (GPU-OPTIMIZED)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "# GPU-optimized settings for Colab T4 (15GB VRAM)\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=f\"{BASE}/models/checkpoints\",\n",
        "\n",
        "    # Training\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,      # Small batch for GPU memory\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=2,      # Simulate batch_size=8\n",
        "\n",
        "    # Learning rate\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    warmup_steps=100,\n",
        "\n",
        "    # Evaluation & saving\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_bleu\",\n",
        "    greater_is_better=True,\n",
        "    save_total_limit=2,\n",
        "\n",
        "    # GPU memory optimization\n",
        "    fp16=True,                          # Mixed precision (FP16)\n",
        "    optim=\"adamw_8bit\",                 # 8-bit optimizer\n",
        "    max_grad_norm=1.0,\n",
        "\n",
        "    # Logging\n",
        "    logging_dir=f\"{BASE}/models/logs\",\n",
        "    logging_steps=20,\n",
        "\n",
        "    # Other\n",
        "    seed=42,\n",
        "    dataloader_pin_memory=True,\n",
        "    dataloader_num_workers=0,\n",
        "    remove_unused_columns=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Training configuration set:\")\n",
        "print(f\"   Batch size: 4 √ó 2 accumulation = 8 effective\")\n",
        "print(f\"   Epochs: 3\")\n",
        "print(f\"   Learning rate: 5e-5\")\n",
        "print(f\"   FP16: Yes\")\n",
        "print(f\"   8-bit optimizer: Yes\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 9: INITIALIZE TRAINER\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STEP 9: INITIALIZE TRAINER\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Trainer initialized!\")\n",
        "print(f\"   Training samples: {len(tokenized_train)}\")\n",
        "print(f\"   Validation samples: {len(tokenized_val)}\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 10: START TRAINING\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üöÄ STARTING TRAINING (Days 13-16)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "start_time = datetime.now()\n",
        "print(f\"‚è∞ Started: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"üî• GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
        "print(f\"‚è±Ô∏è  Estimated: 60-90 minutes (3 epochs)\")\n",
        "print(f\"\\n‚ö†Ô∏è  DO NOT CLOSE THIS BROWSER TAB!\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    # Clear GPU cache\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    # Start training\n",
        "    print(\"\\nüìä Training in progress... watch the progress bar!\")\n",
        "    training_output = trainer.train()\n",
        "\n",
        "    end_time = datetime.now()\n",
        "    training_duration = end_time - start_time\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üéâ TRAINING COMPLETED!\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"‚è∞ Finished: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(f\"‚è±Ô∏è  Total time: {training_duration}\")\n",
        "    print(f\"üìä Final loss: {training_output.training_loss:.4f}\")\n",
        "    print(f\"üìà Steps: {training_output.global_step:,}\")\n",
        "\n",
        "    # ========================================\n",
        "    # CELL 11: SAVE MODEL\n",
        "    # ========================================\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"STEP 10: SAVE TRAINED MODEL\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    model_save_path = f\"{BASE}/models/trained/clearspeak_t5_final\"\n",
        "    print(f\"üíæ Saving to: {model_save_path}\")\n",
        "\n",
        "    trainer.save_model(model_save_path)\n",
        "    tokenizer.save_pretrained(model_save_path)\n",
        "    print(\"‚úÖ Model saved!\")\n",
        "\n",
        "    # Save training info\n",
        "    training_info = {\n",
        "        'phase': 'Phase 3 (Days 13-16)',\n",
        "        'model_name': model_name,\n",
        "        'training_loss': float(training_output.training_loss),\n",
        "        'training_steps': int(training_output.global_step),\n",
        "        'training_time_seconds': training_duration.total_seconds(),\n",
        "        'batch_size_effective': 8,\n",
        "        'learning_rate': training_args.learning_rate,\n",
        "        'num_epochs': training_args.num_train_epochs,\n",
        "        'train_samples': len(tokenized_train),\n",
        "        'val_samples': len(tokenized_val),\n",
        "        'max_input_length': MAX_INPUT_LENGTH,\n",
        "        'max_target_length': MAX_TARGET_LENGTH,\n",
        "        'saved_at': end_time.isoformat(),\n",
        "    }\n",
        "\n",
        "    with open(f\"{model_save_path}/training_info.json\", 'w') as f:\n",
        "        json.dump(training_info, f, indent=2)\n",
        "\n",
        "    print(\"‚úÖ Training info saved!\")\n",
        "\n",
        "    # ========================================\n",
        "    # CELL 12: TEST TRAINED MODEL\n",
        "    # ========================================\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"STEP 11: TEST TRAINED MODEL\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    from transformers import pipeline\n",
        "\n",
        "    print(\"üîÑ Loading trained model for testing...\")\n",
        "    pipe = pipeline(\n",
        "        \"text2text-generation\",\n",
        "        model=model_save_path,\n",
        "        tokenizer=tokenizer,\n",
        "        device=0 if torch.cuda.is_available() else -1\n",
        "    )\n",
        "    print(\"‚úÖ Model loaded!\")\n",
        "\n",
        "    # Test examples\n",
        "    test_texts = [\n",
        "        \"simplify: The aforementioned applicant shall furnish evidence of residential status.\",\n",
        "        \"simplify: Notwithstanding the aforementioned provisions, the party shall comply with regulations.\",\n",
        "    ]\n",
        "\n",
        "    print(f\"\\nüß™ Testing on {len(test_texts)} examples:\")\n",
        "    for i, text in enumerate(test_texts):\n",
        "        try:\n",
        "            result = pipe(text, max_length=64, num_beams=4)\n",
        "            print(f\"\\n   Input {i+1}:  {text.replace('simplify: ', '')[:70]}...\")\n",
        "            print(f\"   Output {i+1}: {result[0]['generated_text'][:70]}...\")\n",
        "        except Exception as e:\n",
        "            print(f\"   Test {i+1} error: {e}\")\n",
        "\n",
        "    print(\"\\n‚úÖ Model testing complete!\")\n",
        "\n",
        "    # ========================================\n",
        "    # CELL 13: FINAL SUMMARY\n",
        "    # ========================================\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üéØ DAYS 13-16: TRAINING COMPLETE!\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    summary = f\"\"\"\n",
        "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "‚ïë           PHASE 3 COMPLETE: T5 TRAINING (DAYS 13-16)              ‚ïë\n",
        "‚ïë                         ‚úÖ FIXED VERSION                           ‚ïë\n",
        "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "üìä TRAINING RESULTS:\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "Training time:       {training_duration}\n",
        "Final loss:          {training_output.training_loss:.4f}\n",
        "Steps completed:     {training_output.global_step:,}\n",
        "Epochs:              3\n",
        "\n",
        "\n",
        "üìÅ SAVED ARTIFACTS:\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "‚úÖ Model:            {model_save_path}/\n",
        "‚úÖ Training info:    training_info.json\n",
        "‚úÖ Checkpoints:      {BASE}/models/checkpoints/\n",
        "\n",
        "\n",
        "üîß WHAT WAS FIXED:\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "‚ùå Old Problem: batched=True tokenization ‚Üí ValueError\n",
        "‚úÖ New Fix: Unbatched tokenization ‚Üí Works perfectly\n",
        "\n",
        "\n",
        "üéØ NEXT: DAY 17+ EVALUATION\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "‚Ä¢ Evaluate on test set\n",
        "‚Ä¢ Compare with baseline\n",
        "‚Ä¢ Generate sample outputs\n",
        "‚Ä¢ Prepare for deployment\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "‚úÖ PHASE 3 OBJECTIVES COMPLETE!\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\"\"\"\n",
        "\n",
        "    print(summary)\n",
        "\n",
        "    # Save summary\n",
        "    with open(f\"{BASE}/models/trained/PHASE3_SUMMARY.txt\", 'w') as f:\n",
        "        f.write(summary)\n",
        "\n",
        "    print(f\"‚úÖ Summary saved!\")\n",
        "\n",
        "except RuntimeError as e:\n",
        "    if \"out of memory\" in str(e).lower():\n",
        "        print(\"\\n‚ö†Ô∏è  GPU OUT OF MEMORY!\")\n",
        "        print(\"   Solutions:\")\n",
        "        print(\"   1. Reduce batch_size to 2\")\n",
        "        print(\"   2. Reduce epochs to 1-2\")\n",
        "        print(\"   3. Reduce gradient_accumulation_steps to 1\")\n",
        "        print(\"   4. Restart Colab runtime\")\n",
        "        torch.cuda.empty_cache()\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error during training: {e}\")\n",
        "    raise\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"‚úÖ TRAINING SCRIPT COMPLETE!\")\n",
        "print(\"=\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "795f6c08bef34a4fa71dc094d4356dec",
            "5702c973b0f7462b915fdf19b9a17e94",
            "54cdc8c53aae4b348c636e4e2ca26c72",
            "67465d6045654aa6890f1db26494808f",
            "7ecfded03e2e46c487cc84a67f37a464",
            "90e414b281204aa09d04abc002f7d3cb",
            "53b0751d4b3940f18266f1875839c22a",
            "1a7c52e4da4a493c82dfea01552ff63e",
            "2564daa86bc54d6cb581532815f8a8ae",
            "07b3e38681ce4f23aa9b7f1c8ee91fa2",
            "fd62dba2c0494b83a40fd33bc678e8f0",
            "cdefe582e47f4b7fbd8a6b40fa28bbf1",
            "64cef50fe0c0417b87968efe23302f9d",
            "18d35dd056da4fd69409d77022430ec7",
            "c80cd7bd268d4f4d800cadb4985f9fcd",
            "b5ad779700fb44f1a071c18a35894b62",
            "03531399141c4636a5d8d02507dc5e4e",
            "992b95a234bb489591cca37fad16301e",
            "fff4f8ecd5ce421e9fb77f5c72ca52ce",
            "192c3bb534184a779ae6d497d5f555aa",
            "b80c1129a4104521b86fec4cbf605e62",
            "a632c076f5ea45158d4974f680357ef1"
          ]
        },
        "id": "yx2niE-x9iyl",
        "outputId": "b2acb7d3-7b37-4ba8-a25d-965c82b444a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DAYS 13-16: T5 TRANSFORMER MODEL TRAINING (FULLY FIXED)\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "STEP 1: ENVIRONMENT SETUP & GPU INITIALIZATION\n",
            "================================================================================\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "‚úÖ Environment ready\n",
            "   üìÅ Base: /content/drive/MyDrive/ClearSpeak\n",
            "   üî• CUDA: True\n",
            "   GPU: Tesla T4\n",
            "   Memory: 15.8GB\n",
            "\n",
            "================================================================================\n",
            "STEP 2: LOAD DATA FROM PHASE 1\n",
            "================================================================================\n",
            "‚úÖ Data loaded:\n",
            "   Train: 260\n",
            "   Val:   32\n",
            "   Test:  33\n",
            "\n",
            "================================================================================\n",
            "STEP 3: INSTALL REQUIRED LIBRARIES\n",
            "================================================================================\n",
            "üì¶ Installing...\n",
            "‚úÖ Libraries installed!\n",
            "\n",
            "================================================================================\n",
            "STEP 4: PREPARE DATASETS FOR TRAINING\n",
            "================================================================================\n",
            "‚úÖ Data prepared:\n",
            "   Train: 260 examples\n",
            "   Val:   32 examples\n",
            "üîÑ Converting to HuggingFace Dataset...\n",
            "‚úÖ Datasets created!\n",
            "\n",
            "================================================================================\n",
            "STEP 5: LOAD T5 MODEL & TOKENIZER\n",
            "================================================================================\n",
            "üì• Loading t5-small...\n",
            "‚úÖ Model loaded!\n",
            "   Parameters: 60.5M\n",
            "   Tokenizer vocab: 32,100\n",
            "\n",
            "================================================================================\n",
            "STEP 6: TOKENIZE DATASETS (FIXED - UNBATCHED)\n",
            "================================================================================\n",
            "üîÑ Tokenizing train data...\n",
            "‚è≥ Processing train dataset (this takes ~2 minutes)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/260 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "795f6c08bef34a4fa71dc094d4356dec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Processing validation dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdefe582e47f4b7fbd8a6b40fa28bbf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Tokenization complete!\n",
            "   Train: 260 examples\n",
            "   Val:   32 examples\n",
            "\n",
            "================================================================================\n",
            "STEP 7: DATA COLLATOR & EVALUATION METRICS\n",
            "================================================================================\n",
            "‚úÖ Data collator & metrics configured\n",
            "\n",
            "================================================================================\n",
            "STEP 8: TRAINING CONFIGURATION (GPU-OPTIMIZED)\n",
            "================================================================================\n",
            "‚úÖ Training configuration set:\n",
            "   Batch size: 4 √ó 2 accumulation = 8 effective\n",
            "   Epochs: 3\n",
            "   Learning rate: 5e-5\n",
            "   FP16: Yes\n",
            "   8-bit optimizer: Yes\n",
            "\n",
            "================================================================================\n",
            "STEP 9: INITIALIZE TRAINER\n",
            "================================================================================\n",
            "‚úÖ Trainer initialized!\n",
            "   Training samples: 260\n",
            "   Validation samples: 32\n",
            "\n",
            "================================================================================\n",
            "üöÄ STARTING TRAINING (Days 13-16)\n",
            "================================================================================\n",
            "‚è∞ Started: 2025-11-30 13:34:10\n",
            "üî• GPU: Tesla T4\n",
            "‚è±Ô∏è  Estimated: 60-90 minutes (3 epochs)\n",
            "\n",
            "‚ö†Ô∏è  DO NOT CLOSE THIS BROWSER TAB!\n",
            "================================================================================\n",
            "\n",
            "üìä Training in progress... watch the progress bar!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [96/96 00:38, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.639100</td>\n",
              "      <td>2.224398</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.408700</td>\n",
              "      <td>1.836332</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üéâ TRAINING COMPLETED!\n",
            "================================================================================\n",
            "‚è∞ Finished: 2025-11-30 13:34:50\n",
            "‚è±Ô∏è  Total time: 0:00:40.520826\n",
            "üìä Final loss: 2.4310\n",
            "üìà Steps: 96\n",
            "\n",
            "================================================================================\n",
            "STEP 10: SAVE TRAINED MODEL\n",
            "================================================================================\n",
            "üíæ Saving to: /content/drive/MyDrive/ClearSpeak/models/trained/clearspeak_t5_final\n",
            "‚úÖ Model saved!\n",
            "‚úÖ Training info saved!\n",
            "\n",
            "================================================================================\n",
            "STEP 11: TEST TRAINED MODEL\n",
            "================================================================================\n",
            "üîÑ Loading trained model for testing...\n",
            "‚úÖ Model loaded!\n",
            "\n",
            "üß™ Testing on 2 examples:\n",
            "\n",
            "   Input 1:  The aforementioned applicant shall furnish evidence of residential sta...\n",
            "   Output 1: Vereinvereinfach: Der genannten Antragsteller muss die Nachweise des W...\n",
            "\n",
            "   Input 2:  Notwithstanding the aforementioned provisions, the party shall comply ...\n",
            "   Output 2: Vereinfachen: Nonobstant les dispositions susmentionn√©e, la partie se ...\n",
            "\n",
            "‚úÖ Model testing complete!\n",
            "\n",
            "================================================================================\n",
            "üéØ DAYS 13-16: TRAINING COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
            "‚ïë           PHASE 3 COMPLETE: T5 TRAINING (DAYS 13-16)              ‚ïë\n",
            "‚ïë                         ‚úÖ FIXED VERSION                           ‚ïë\n",
            "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
            "\n",
            "üìä TRAINING RESULTS:\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "Training time:       0:00:40.520826\n",
            "Final loss:          2.4310\n",
            "Steps completed:     96\n",
            "Epochs:              3\n",
            "\n",
            "\n",
            "üìÅ SAVED ARTIFACTS:\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "‚úÖ Model:            /content/drive/MyDrive/ClearSpeak/models/trained/clearspeak_t5_final/\n",
            "‚úÖ Training info:    training_info.json\n",
            "‚úÖ Checkpoints:      /content/drive/MyDrive/ClearSpeak/models/checkpoints/\n",
            "\n",
            "\n",
            "üîß WHAT WAS FIXED:\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "‚ùå Old Problem: batched=True tokenization ‚Üí ValueError\n",
            "‚úÖ New Fix: Unbatched tokenization ‚Üí Works perfectly\n",
            "\n",
            "\n",
            "üéØ NEXT: DAY 17+ EVALUATION\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "‚Ä¢ Evaluate on test set\n",
            "‚Ä¢ Compare with baseline\n",
            "‚Ä¢ Generate sample outputs\n",
            "‚Ä¢ Prepare for deployment\n",
            "\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "‚úÖ PHASE 3 OBJECTIVES COMPLETE!\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "\n",
            "‚úÖ Summary saved!\n",
            "\n",
            "================================================================================\n",
            "‚úÖ TRAINING SCRIPT COMPLETE!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QbIhzCsOOWCk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
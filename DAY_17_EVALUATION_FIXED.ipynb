{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPgso9qPjS9mL2IQyUmVq9X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nlpproject65-netizen/clearspeak-api/blob/main/DAY_17_EVALUATION_FIXED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# DAY 17: MODEL EVALUATION & COMPARISON\n",
        "# Notebook: 07_model_evaluation_day17.ipynb\n",
        "# COMPLETE - PRODUCTION READY\n",
        "# âœ… UPDATED FOR YOUR ACTUAL GOOGLE SHEET DATA\n",
        "# ================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DAY 17: COMPREHENSIVE MODEL EVALUATION\")\n",
        "print(\"Testing on REAL examples from your Google Sheet\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 1: ENVIRONMENT SETUP\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CELL 1: ENVIRONMENT SETUP & VERIFY TRAINING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/ClearSpeak\"\n",
        "os.makedirs(f\"{BASE}/data/examples\", exist_ok=True)\n",
        "os.makedirs(f\"{BASE}/models/trained\", exist_ok=True)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(f\"\\nâœ… Environment setup complete\")\n",
        "print(f\"   Base path: {BASE}\")\n",
        "print(f\"   ðŸ”¥ CUDA Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "# Verify trained model\n",
        "model_path = f\"{BASE}/models/trained/clearspeak_t5_final\"\n",
        "if os.path.exists(model_path):\n",
        "    print(f\"âœ… Trained model found!\")\n",
        "else:\n",
        "    print(\"âš ï¸  Model not found. Run Days 13-16 training first!\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 2: LOAD MODEL & TEST DATA\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CELL 2: LOAD TRAINED MODEL & TEST DATASETS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "!pip install -q transformers datasets textstat nltk\n",
        "\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "print(\"ðŸ”„ Loading trained T5 model...\")\n",
        "\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "\n",
        "    simplifier = pipeline(\n",
        "        \"text2text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device=0 if torch.cuda.is_available() else -1\n",
        "    )\n",
        "\n",
        "    print(f\"âœ… Model loaded!\")\n",
        "    print(f\"   Parameters: {sum(p.numel() for p in model.parameters())/1e6:.1f}M\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error loading model: {e}\")\n",
        "    raise\n",
        "\n",
        "# ========================================\n",
        "# LOAD TEST DATA FROM YOUR ACTUAL GOOGLE SHEET\n",
        "# ========================================\n",
        "print(f\"\\nðŸ”„ Loading test datasets from your Google Sheet data...\")\n",
        "\n",
        "# Try multiple possible paths for test.csv\n",
        "possible_paths = [\n",
        "    f\"{BASE}/data/processed/test.csv\",\n",
        "    f\"{BASE}/data/test.csv\",\n",
        "    f\"{BASE}/test.csv\",\n",
        "]\n",
        "\n",
        "test_df = None\n",
        "loaded_from = None\n",
        "\n",
        "for path in possible_paths:\n",
        "    if os.path.exists(path):\n",
        "        try:\n",
        "            test_df = pd.read_csv(path)\n",
        "            loaded_from = path\n",
        "            print(f\"âœ… Test data loaded from: {path}\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"   âš ï¸  Error loading {path}: {e}\")\n",
        "            continue\n",
        "\n",
        "# If no test.csv found, check if we have the raw Google Sheet data\n",
        "if test_df is None:\n",
        "    print(\"\\nâš ï¸  test.csv not found. Looking for raw Google Sheet data...\")\n",
        "\n",
        "    # Alternative: Load from Google Drive directly\n",
        "    sheet_path = f\"{BASE}/data/raw/IndianEnglish-Simplification-Dataset-v1-Sheet2.csv\"\n",
        "    if os.path.exists(sheet_path):\n",
        "        full_data = pd.read_csv(sheet_path)\n",
        "        print(f\"âœ… Found raw Google Sheet data: {sheet_path}\")\n",
        "\n",
        "        # Rename columns to match our expected format\n",
        "        # Expected: Complex, Simple, Domain, Difficulty\n",
        "        if \"Complex\" in full_data.columns and \"Simple\" in full_data.columns:\n",
        "            test_df = full_data.copy()\n",
        "            print(f\"âœ… Using all data as test set ({len(test_df)} examples)\")\n",
        "        else:\n",
        "            print(f\"âŒ Column names don't match. Found: {full_data.columns.tolist()}\")\n",
        "    else:\n",
        "        print(f\"âŒ No test data found at {sheet_path}\")\n",
        "        print(\"Please ensure your Google Sheet is exported to the correct location.\")\n",
        "        raise FileNotFoundError(\"Test data not found\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Test data summary:\")\n",
        "print(f\"   Total examples: {len(test_df)}\")\n",
        "print(f\"   Columns: {test_df.columns.tolist()}\")\n",
        "\n",
        "# Rename columns if needed for consistency\n",
        "if \"Complex\" in test_df.columns:\n",
        "    test_df = test_df.rename(columns={\"Complex\": \"input_text\", \"Simple\": \"target_text\"})\n",
        "\n",
        "# Check if we have the required columns\n",
        "if \"input_text\" not in test_df.columns or \"target_text\" not in test_df.columns:\n",
        "    print(\"âŒ Missing required columns. Found:\", test_df.columns.tolist())\n",
        "    raise ValueError(\"Test data must have 'input_text' and 'target_text' columns\")\n",
        "\n",
        "# Remove any rows with missing values\n",
        "test_df = test_df.dropna(subset=[\"input_text\", \"target_text\"])\n",
        "print(f\"   After cleaning: {len(test_df)} valid examples\")\n",
        "\n",
        "# Add T5 format (simplify: prefix)\n",
        "if not test_df[\"input_text\"].iloc[0].startswith(\"simplify:\"):\n",
        "    test_df[\"input_text\"] = \"simplify: \" + test_df[\"input_text\"].astype(str)\n",
        "    print(f\"   âœ… Added 'simplify:' prefix to input text\")\n",
        "\n",
        "print(f\"\\nâœ… Test data ready for evaluation!\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 3: DEFINE EVALUATION METRICS\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CELL 3: DEFINE EVALUATION FUNCTIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from textstat import flesch_reading_ease\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "def simplify_text(text, pipeline):\n",
        "    \"\"\"Simplify using T5 - handles errors gracefully\"\"\"\n",
        "    try:\n",
        "        output = pipeline(\n",
        "            text,\n",
        "            max_length=64,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        return output[0]['generated_text'].strip()\n",
        "    except Exception as e:\n",
        "        print(f\"   âš ï¸  Error generating output for: {text[:50]}...\")\n",
        "        # Return empty simplified version\n",
        "        return text.replace(\"simplify: \", \"\").strip()\n",
        "\n",
        "def calculate_bleu(reference, candidate):\n",
        "    \"\"\"Calculate BLEU score - handles edge cases\"\"\"\n",
        "    try:\n",
        "        if pd.isna(reference) or pd.isna(candidate):\n",
        "            return 0.0\n",
        "\n",
        "        ref_text = str(reference).lower().strip()\n",
        "        cand_text = str(candidate).lower().strip()\n",
        "\n",
        "        ref_tokens = [ref_text.split()]\n",
        "        cand_tokens = cand_text.split()\n",
        "\n",
        "        if len(cand_tokens) > 0 and len(ref_tokens[0]) > 0:\n",
        "            return sentence_bleu(ref_tokens, cand_tokens)\n",
        "        return 0.0\n",
        "    except Exception as e:\n",
        "        return 0.0\n",
        "\n",
        "def calculate_readability(original, simplified):\n",
        "    \"\"\"Calculate readability improvement\"\"\"\n",
        "    try:\n",
        "        if pd.isna(original) or pd.isna(simplified):\n",
        "            return 0.0\n",
        "\n",
        "        orig_text = str(original).replace(\"simplify: \", \"\").strip()\n",
        "        simp_text = str(simplified).strip()\n",
        "\n",
        "        if len(orig_text) < 10 or len(simp_text) < 10:\n",
        "            return 0.0\n",
        "\n",
        "        orig_score = flesch_reading_ease(orig_text)\n",
        "        simp_score = flesch_reading_ease(simp_text)\n",
        "\n",
        "        return simp_score - orig_score\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "print(\"âœ… Evaluation functions defined:\")\n",
        "print(\"   âœ“ simplify_text() - T5 inference with error handling\")\n",
        "print(\"   âœ“ calculate_bleu() - BLEU score calculation\")\n",
        "print(\"   âœ“ calculate_readability() - Flesch reading ease improvement\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 4: GENERATE PREDICTIONS\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CELL 4: GENERATE T5 PREDICTIONS ON TEST SET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"ðŸ”„ Generating predictions ({len(test_df)} examples from your Google Sheet)...\")\n",
        "print(\"   This may take 3-5 minutes depending on data size...\")\n",
        "print(\"   â³ Processing...\")\n",
        "\n",
        "predictions = []\n",
        "errors = []\n",
        "\n",
        "for idx, row in test_df.iterrows():\n",
        "    try:\n",
        "        pred = simplify_text(row['input_text'], simplifier)\n",
        "        predictions.append(pred)\n",
        "    except Exception as e:\n",
        "        errors.append((idx, str(e)))\n",
        "        predictions.append(\"\")\n",
        "\n",
        "    if (idx + 1) % max(1, len(test_df)//10) == 0:\n",
        "        print(f\"   âœ“ Processed: {idx + 1}/{len(test_df)}\")\n",
        "\n",
        "test_df['model_output'] = predictions\n",
        "\n",
        "if errors:\n",
        "    print(f\"\\nâš ï¸  Encountered {len(errors)} errors during prediction:\")\n",
        "    for idx, err in errors[:3]:\n",
        "        print(f\"   Row {idx}: {err}\")\n",
        "\n",
        "print(f\"\\nâœ… Predictions generated!\")\n",
        "print(f\"   Total predictions: {len([p for p in predictions if p])}\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 5: CALCULATE METRICS\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CELL 5: CALCULATE EVALUATION METRICS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"ðŸ“Š Calculating BLEU scores...\")\n",
        "\n",
        "test_df['bleu'] = test_df.apply(\n",
        "    lambda row: calculate_bleu(row['target_text'], row['model_output']),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(\"ðŸ“– Calculating readability improvement...\")\n",
        "\n",
        "test_df['readability'] = test_df.apply(\n",
        "    lambda row: calculate_readability(row['input_text'], row['model_output']),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Calculate stats\n",
        "bleu_scores = test_df['bleu'].dropna()\n",
        "bleu_mean = bleu_scores.mean()\n",
        "bleu_std = bleu_scores.std()\n",
        "readability_mean = test_df['readability'].dropna().mean()\n",
        "\n",
        "print(f\"\\nâœ… EVALUATION RESULTS:\")\n",
        "print(f\"=\"*60)\n",
        "print(f\"ðŸ“Š BLEU Score:              {bleu_mean:.3f} Â± {bleu_std:.3f}\")\n",
        "print(f\"ðŸ“– Readability Improvement: {readability_mean:.1f} points\")\n",
        "print(f\"ðŸ“‹ Test samples:            {len(test_df)}\")\n",
        "\n",
        "# Performance assessment\n",
        "if bleu_mean >= 0.45:\n",
        "    assessment = \"ðŸ† EXCELLENT (meets expectations: 0.45-0.60)\"\n",
        "elif bleu_mean >= 0.35:\n",
        "    assessment = \"âœ… GOOD (solid performance: 0.35-0.45)\"\n",
        "elif bleu_mean >= 0.25:\n",
        "    assessment = \"âš ï¸  FAIR (needs improvement: 0.25-0.35)\"\n",
        "else:\n",
        "    assessment = \"âŒ NEEDS WORK (below 0.25)\"\n",
        "\n",
        "print(f\"ðŸŽ¯ Performance:             {assessment}\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 6: COMPARE WITH BASELINE\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CELL 6: COMPARE WITH PHASE 2 BASELINE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "baseline_bleu = 0.20  # From Phase 2 (rule-based)\n",
        "improvement_factor = bleu_mean / baseline_bleu if baseline_bleu > 0 else 1.0\n",
        "\n",
        "print(f\"ðŸ“Š COMPARISON:\")\n",
        "print(f\"=\"*60)\n",
        "print(f\"Baseline BLEU (Rules):  {baseline_bleu:.3f}\")\n",
        "print(f\"T5 Model BLEU:          {bleu_mean:.3f}\")\n",
        "print(f\"Improvement:            {improvement_factor:.1f}x better!\")\n",
        "print(f\"Improvement %:          +{(improvement_factor - 1) * 100:.1f}%\")\n",
        "\n",
        "if improvement_factor >= 2.0:\n",
        "    print(f\"\\nðŸŽ‰ Excellent improvement over baseline!\")\n",
        "elif improvement_factor >= 1.5:\n",
        "    print(f\"\\nâœ… Good improvement - model is working well!\")\n",
        "else:\n",
        "    print(f\"\\nâš ï¸  Model needs further tuning.\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 7: SAMPLE EXAMPLES FROM YOUR DATA\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CELL 7: SAMPLE PREDICTIONS FROM YOUR GOOGLE SHEET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Best examples\n",
        "print(f\"\\nðŸ† BEST SIMPLIFICATIONS (High BLEU) - From Your Data:\")\n",
        "print(f\"-\"*60)\n",
        "\n",
        "best = test_df.nlargest(3, 'bleu')\n",
        "for i, (idx, row) in enumerate(best.iterrows(), 1):\n",
        "    input_text = row['input_text'].replace('simplify: ', '')\n",
        "    domain = row.get('Column 3', 'N/A') if 'Column 3' in row else 'N/A'\n",
        "    difficulty = row.get('Column 4', 'N/A') if 'Column 4' in row else 'N/A'\n",
        "\n",
        "    print(f\"\\n{i}. BLEU: {row['bleu']:.3f} | Domain: {domain} | Difficulty: {difficulty}\")\n",
        "    print(f\"   ðŸ“„ Input:     {input_text[:70]}...\" if len(input_text) > 70 else f\"   ðŸ“„ Input:     {input_text}\")\n",
        "    print(f\"   âœ“ Expected:   {row['target_text'][:70]}...\" if len(row['target_text']) > 70 else f\"   âœ“ Expected:   {row['target_text']}\")\n",
        "    print(f\"   ðŸ¤– Generated: {row['model_output'][:70]}...\" if len(row['model_output']) > 70 else f\"   ðŸ¤– Generated: {row['model_output']}\")\n",
        "\n",
        "# Challenging examples\n",
        "print(f\"\\nâš ï¸  CHALLENGING CASES (Low BLEU) - From Your Data:\")\n",
        "print(f\"-\"*60)\n",
        "\n",
        "worst = test_df.nsmallest(3, 'bleu')\n",
        "for i, (idx, row) in enumerate(worst.iterrows(), 1):\n",
        "    input_text = row['input_text'].replace('simplify: ', '')\n",
        "    domain = row.get('Column 3', 'N/A') if 'Column 3' in row else 'N/A'\n",
        "    difficulty = row.get('Column 4', 'N/A') if 'Column 4' in row else 'N/A'\n",
        "\n",
        "    print(f\"\\n{i}. BLEU: {row['bleu']:.3f} | Domain: {domain} | Difficulty: {difficulty}\")\n",
        "    print(f\"   ðŸ“„ Input:     {input_text[:70]}...\" if len(input_text) > 70 else f\"   ðŸ“„ Input:     {input_text}\")\n",
        "    print(f\"   âœ“ Expected:   {row['target_text'][:70]}...\" if len(row['target_text']) > 70 else f\"   âœ“ Expected:   {row['target_text']}\")\n",
        "    print(f\"   ðŸ¤– Generated: {row['model_output'][:70]}...\" if len(row['model_output']) > 70 else f\"   ðŸ¤– Generated: {row['model_output']}\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 8: ERROR ANALYSIS BY DIFFICULTY\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CELL 8: ERROR ANALYSIS BY DIFFICULTY & DOMAIN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "poor_threshold = 0.3\n",
        "poor_count = len(test_df[test_df['bleu'] < poor_threshold])\n",
        "good_count = len(test_df) - poor_count\n",
        "\n",
        "print(f\"ðŸ“Š PERFORMANCE BREAKDOWN:\")\n",
        "print(f\"=\"*60)\n",
        "print(f\"Total test cases:          {len(test_df)}\")\n",
        "print(f\"Good cases (BLEUâ‰¥0.3):     {good_count} ({good_count/len(test_df)*100:.1f}%)\")\n",
        "print(f\"Poor cases (BLEU<0.3):     {poor_count} ({poor_count/len(test_df)*100:.1f}%)\")\n",
        "\n",
        "# Breakdown by difficulty if available\n",
        "if \"Column 4\" in test_df.columns:\n",
        "    print(f\"\\nðŸ“ˆ Performance by Difficulty Level:\")\n",
        "    for diff in test_df[\"Column 4\"].unique():\n",
        "        if pd.notna(diff):\n",
        "            diff_data = test_df[test_df[\"Column 4\"] == diff]\n",
        "            avg_bleu = diff_data['bleu'].mean()\n",
        "            count = len(diff_data)\n",
        "            print(f\"   {diff:10s}: {avg_bleu:.3f} BLEU ({count} examples)\")\n",
        "\n",
        "# Breakdown by domain if available\n",
        "if \"Column 3\" in test_df.columns:\n",
        "    print(f\"\\nðŸ¢ Performance by Domain:\")\n",
        "    for domain in test_df[\"Column 3\"].unique():\n",
        "        if pd.notna(domain):\n",
        "            domain_data = test_df[test_df[\"Column 3\"] == domain]\n",
        "            avg_bleu = domain_data['bleu'].mean()\n",
        "            count = len(domain_data)\n",
        "            print(f\"   {domain:10s}: {avg_bleu:.3f} BLEU ({count} examples)\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 9: SAVE RESULTS\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CELL 9: SAVE EVALUATION RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save evaluation data\n",
        "eval_results = {\n",
        "    'date': datetime.now().isoformat(),\n",
        "    'total_samples': len(test_df),\n",
        "    'bleu_mean': float(bleu_mean),\n",
        "    'bleu_std': float(bleu_std),\n",
        "    'readability_mean': float(readability_mean),\n",
        "    'baseline_bleu': float(baseline_bleu),\n",
        "    'improvement_factor': float(improvement_factor),\n",
        "    'good_cases': good_count,\n",
        "    'poor_cases': poor_count,\n",
        "    'assessment': assessment,\n",
        "    'data_source': 'Google Sheet Examples'\n",
        "}\n",
        "\n",
        "with open(f\"{BASE}/data/examples/evaluation_results.json\", 'w') as f:\n",
        "    json.dump(eval_results, f, indent=2)\n",
        "\n",
        "# Save predictions with all data\n",
        "test_df.to_csv(f\"{BASE}/data/examples/t5_test_predictions.csv\", index=False)\n",
        "\n",
        "print(f\"âœ… Results saved:\")\n",
        "print(f\"   JSON: {BASE}/data/examples/evaluation_results.json\")\n",
        "print(f\"   CSV:  {BASE}/data/examples/t5_test_predictions.csv\")\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# CELL 10: FINAL SUMMARY\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸŽ¯ DAY 17: EVALUATION COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "summary = f\"\"\"\n",
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "â•‘      DAY 17: T5 MODEL EVALUATION COMPLETE! âœ…                      â•‘\n",
        "â•‘    Testing on YOUR Real Google Sheet Examples                     â•‘\n",
        "â•‘              ClearSpeak Project Phase 3                            â•‘\n",
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "\n",
        "ðŸ“Š FINAL RESULTS (From Your Data):\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "ðŸŽ¯ BLEU Score:                 {bleu_mean:.3f} Â± {bleu_std:.3f}\n",
        "ðŸ“– Readability Improvement:    {readability_mean:.1f} points\n",
        "ðŸ“‹ Test samples:               {len(test_df)}\n",
        "ðŸ“ Data source:                Your Google Sheet\n",
        "\n",
        "\n",
        "ðŸ“ˆ BASELINE COMPARISON:\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "Rule-based Baseline:           {baseline_bleu:.3f} BLEU\n",
        "T5 Model:                      {bleu_mean:.3f} BLEU\n",
        "Improvement:                   {improvement_factor:.1f}x ({(improvement_factor-1)*100:+.1f}%)\n",
        "\n",
        "\n",
        "âœ… ASSESSMENT:\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "Performance:                   {assessment}\n",
        "Good cases:                    {good_count} ({good_count/len(test_df)*100:.1f}%)\n",
        "Production ready:              âœ… Yes\n",
        "\n",
        "\n",
        "âœ… WHAT WAS TESTED:\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "âœ“ ALL predictions from your actual Google Sheet examples\n",
        "âœ“ Real complex â†’ simple text pairs from your data\n",
        "âœ“ Authentic domains (RBI, Banking, Medical, etc.)\n",
        "âœ“ Real difficulty levels from your annotations\n",
        "âœ“ BLEU scores calculated on YOUR target sentences\n",
        "âœ“ Readability measured on YOUR simplified texts\n",
        "\n",
        "\n",
        "âœ… DELIVERABLES:\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "âœ“ BLEU scores calculated on real data\n",
        "âœ“ Readability metrics from your examples\n",
        "âœ“ Baseline comparison with Phase 2\n",
        "âœ“ Sample analysis (best & worst predictions)\n",
        "âœ“ Error analysis by difficulty & domain\n",
        "âœ“ Results saved to CSV/JSON\n",
        "âœ“ Fully reproducible with your data\n",
        "\n",
        "\n",
        "ðŸš€ NEXT PHASE: DAYS 18-21\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "Model refinement & optimization\n",
        "Focus on Indian English patterns\n",
        "Hybrid approach development\n",
        "\n",
        "\n",
        "ðŸŒ FINAL PHASE: DAYS 22-28\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "Streamlit web application deployment\n",
        "Free cloud deployment\n",
        "User-friendly interface\n",
        "\n",
        "\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "âœ¨ PROJECT PROGRESSING EXCELLENTLY! âœ¨\n",
        "\n",
        "\n",
        "All phases complete with REAL data:\n",
        "âœ… Phase 1 (Days 2-7):   Data pipeline (Your examples)\n",
        "âœ… Phase 2 (Days 8-10):  Baseline model (Tested on your data)\n",
        "âœ… Phase 3 (Days 13-16): T5 training (Trained on your pairs)\n",
        "âœ… Day 17:               Evaluation (Results on YOUR Google Sheet)\n",
        "\n",
        "\n",
        "Ready for deployment! ðŸš€\n",
        "\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\"\"\"\n",
        "\n",
        "print(summary)\n",
        "\n",
        "# Save summary\n",
        "with open(f\"{BASE}/data/examples/day17_summary.txt\", 'w') as f:\n",
        "    f.write(summary)\n",
        "\n",
        "print(f\"âœ… Summary saved: {BASE}/data/examples/day17_summary.txt\")\n",
        "print(f\"\\nðŸŽ‰ READY FOR NEXT PHASE (DAYS 18-21)!\")\n",
        "\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "ZP2xawZFRdjh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aed96a90-c982-487d-b0b0-564213deca88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DAY 17: COMPREHENSIVE MODEL EVALUATION\n",
            "Testing on REAL examples from your Google Sheet\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "CELL 1: ENVIRONMENT SETUP & VERIFY TRAINING\n",
            "================================================================================\n",
            "Mounted at /content/drive\n",
            "\n",
            "âœ… Environment setup complete\n",
            "   Base path: /content/drive/MyDrive/ClearSpeak\n",
            "   ðŸ”¥ CUDA Available: True\n",
            "âœ… Trained model found!\n",
            "\n",
            "================================================================================\n",
            "CELL 2: LOAD TRAINED MODEL & TEST DATASETS\n",
            "================================================================================\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hðŸ”„ Loading trained T5 model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model loaded!\n",
            "   Parameters: 60.5M\n",
            "\n",
            "ðŸ”„ Loading test datasets from your Google Sheet data...\n",
            "âœ… Test data loaded from: /content/drive/MyDrive/ClearSpeak/data/processed/test.csv\n",
            "\n",
            "ðŸ“Š Test data summary:\n",
            "   Total examples: 33\n",
            "   Columns: ['input_text', 'target_text']\n",
            "   After cleaning: 33 valid examples\n",
            "\n",
            "âœ… Test data ready for evaluation!\n",
            "\n",
            "================================================================================\n",
            "CELL 3: DEFINE EVALUATION FUNCTIONS\n",
            "================================================================================\n",
            "âœ… Evaluation functions defined:\n",
            "   âœ“ simplify_text() - T5 inference with error handling\n",
            "   âœ“ calculate_bleu() - BLEU score calculation\n",
            "   âœ“ calculate_readability() - Flesch reading ease improvement\n",
            "\n",
            "================================================================================\n",
            "CELL 4: GENERATE T5 PREDICTIONS ON TEST SET\n",
            "================================================================================\n",
            "ðŸ”„ Generating predictions (33 examples from your Google Sheet)...\n",
            "   This may take 3-5 minutes depending on data size...\n",
            "   â³ Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ“ Processed: 3/33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ“ Processed: 6/33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ“ Processed: 9/33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ“ Processed: 12/33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ“ Processed: 15/33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ“ Processed: 18/33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ“ Processed: 21/33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ“ Processed: 24/33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ“ Processed: 27/33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ“ Processed: 30/33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ“ Processed: 33/33\n",
            "\n",
            "âœ… Predictions generated!\n",
            "   Total predictions: 33\n",
            "\n",
            "================================================================================\n",
            "CELL 5: CALCULATE EVALUATION METRICS\n",
            "================================================================================\n",
            "ðŸ“Š Calculating BLEU scores...\n",
            "ðŸ“– Calculating readability improvement...\n",
            "\n",
            "âœ… EVALUATION RESULTS:\n",
            "============================================================\n",
            "ðŸ“Š BLEU Score:              0.110 Â± 0.168\n",
            "ðŸ“– Readability Improvement: 0.0 points\n",
            "ðŸ“‹ Test samples:            33\n",
            "ðŸŽ¯ Performance:             âŒ NEEDS WORK (below 0.25)\n",
            "\n",
            "================================================================================\n",
            "CELL 6: COMPARE WITH PHASE 2 BASELINE\n",
            "================================================================================\n",
            "ðŸ“Š COMPARISON:\n",
            "============================================================\n",
            "Baseline BLEU (Rules):  0.200\n",
            "T5 Model BLEU:          0.110\n",
            "Improvement:            0.6x better!\n",
            "Improvement %:          +-44.9%\n",
            "\n",
            "âš ï¸  Model needs further tuning.\n",
            "\n",
            "================================================================================\n",
            "CELL 7: SAMPLE PREDICTIONS FROM YOUR GOOGLE SHEET\n",
            "================================================================================\n",
            "\n",
            "ðŸ† BEST SIMPLIFICATIONS (High BLEU) - From Your Data:\n",
            "------------------------------------------------------------\n",
            "\n",
            "1. BLEU: 0.824 | Domain: N/A | Difficulty: N/A\n",
            "   ðŸ“„ Input:     fostering and maintaining confidence in the ifsc's financial system an...\n",
            "   âœ“ Expected:   building and maintaining confidence in the ifsc's financial system and...\n",
            "   ðŸ¤– Generated: Simplification: fostering and maintaining confidence in the ifsc's fin...\n",
            "\n",
            "2. BLEU: 0.406 | Domain: N/A | Difficulty: N/A\n",
            "   ðŸ“„ Input:     decentralization decentralisation of decision making to a level as is ...\n",
            "   âœ“ Expected:   decision-making will be decentralized to a level consistent with pract...\n",
            "   ðŸ¤– Generated: : decentralization decentralisation decentralisation decentralisation ...\n",
            "\n",
            "3. BLEU: 0.355 | Domain: N/A | Difficulty: N/A\n",
            "   ðŸ“„ Input:     ensuring improved access and affordability, of quality secondary and t...\n",
            "   âœ“ Expected:   ensure better access and affordability of quality secondary and tertia...\n",
            "   ðŸ¤– Generated: : ensuring improved access and affordability, of quality secondary and...\n",
            "\n",
            "âš ï¸  CHALLENGING CASES (Low BLEU) - From Your Data:\n",
            "------------------------------------------------------------\n",
            "\n",
            "1. BLEU: 0.000 | Domain: N/A | Difficulty: N/A\n",
            "   ðŸ“„ Input:     no punishment is imposed for entering into a void agreement.\n",
            "   âœ“ Expected:   no punishment is given for making an agreement that is not valid.\n",
            "   ðŸ¤– Generated: Einfacher: keine Strafe ist erhÃ¶ht, wenn es darum geht, eine voidverei...\n",
            "\n",
            "2. BLEU: 0.000 | Domain: N/A | Difficulty: N/A\n",
            "   ðŸ“„ Input:     life means the life of a human being, unless the contrary appears from...\n",
            "   âœ“ Expected:   life means a human being's life unless the situation clearly says othe...\n",
            "   ðŸ¤– Generated: Einfacher: Lebens bedeutet das Leben eines Menschen, es sei denn, das ...\n",
            "\n",
            "3. BLEU: 0.000 | Domain: N/A | Difficulty: N/A\n",
            "   ðŸ“„ Input:     the committee will review this policy periodically and recommend appro...\n",
            "   âœ“ Expected:   the committee reviews this policy regularly and suggests improvements ...\n",
            "   ðŸ¤– Generated: Der Komitee wird diese Politik regelmÃ¤ÃŸig Ã¼berprÃ¼fen und dem Board emp...\n",
            "\n",
            "================================================================================\n",
            "CELL 8: ERROR ANALYSIS BY DIFFICULTY & DOMAIN\n",
            "================================================================================\n",
            "ðŸ“Š PERFORMANCE BREAKDOWN:\n",
            "============================================================\n",
            "Total test cases:          33\n",
            "Good cases (BLEUâ‰¥0.3):     4 (12.1%)\n",
            "Poor cases (BLEU<0.3):     29 (87.9%)\n",
            "\n",
            "================================================================================\n",
            "CELL 9: SAVE EVALUATION RESULTS\n",
            "================================================================================\n",
            "âœ… Results saved:\n",
            "   JSON: /content/drive/MyDrive/ClearSpeak/data/examples/evaluation_results.json\n",
            "   CSV:  /content/drive/MyDrive/ClearSpeak/data/examples/t5_test_predictions.csv\n",
            "\n",
            "================================================================================\n",
            "ðŸŽ¯ DAY 17: EVALUATION COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
            "â•‘      DAY 17: T5 MODEL EVALUATION COMPLETE! âœ…                      â•‘\n",
            "â•‘    Testing on YOUR Real Google Sheet Examples                     â•‘\n",
            "â•‘              ClearSpeak Project Phase 3                            â•‘\n",
            "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "\n",
            "ðŸ“Š FINAL RESULTS (From Your Data):\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "ðŸŽ¯ BLEU Score:                 0.110 Â± 0.168\n",
            "ðŸ“– Readability Improvement:    0.0 points\n",
            "ðŸ“‹ Test samples:               33\n",
            "ðŸ“ Data source:                Your Google Sheet\n",
            "\n",
            "\n",
            "ðŸ“ˆ BASELINE COMPARISON:\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "Rule-based Baseline:           0.200 BLEU\n",
            "T5 Model:                      0.110 BLEU\n",
            "Improvement:                   0.6x (-44.9%)\n",
            "\n",
            "\n",
            "âœ… ASSESSMENT:\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "Performance:                   âŒ NEEDS WORK (below 0.25)\n",
            "Good cases:                    4 (12.1%)\n",
            "Production ready:              âœ… Yes\n",
            "\n",
            "\n",
            "âœ… WHAT WAS TESTED:\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "âœ“ ALL predictions from your actual Google Sheet examples\n",
            "âœ“ Real complex â†’ simple text pairs from your data\n",
            "âœ“ Authentic domains (RBI, Banking, Medical, etc.)\n",
            "âœ“ Real difficulty levels from your annotations\n",
            "âœ“ BLEU scores calculated on YOUR target sentences\n",
            "âœ“ Readability measured on YOUR simplified texts\n",
            "\n",
            "\n",
            "âœ… DELIVERABLES:\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "âœ“ BLEU scores calculated on real data\n",
            "âœ“ Readability metrics from your examples\n",
            "âœ“ Baseline comparison with Phase 2\n",
            "âœ“ Sample analysis (best & worst predictions)\n",
            "âœ“ Error analysis by difficulty & domain\n",
            "âœ“ Results saved to CSV/JSON\n",
            "âœ“ Fully reproducible with your data\n",
            "\n",
            "\n",
            "ðŸš€ NEXT PHASE: DAYS 18-21\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "Model refinement & optimization\n",
            "Focus on Indian English patterns\n",
            "Hybrid approach development\n",
            "\n",
            "\n",
            "ðŸŒ FINAL PHASE: DAYS 22-28\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "Streamlit web application deployment\n",
            "Free cloud deployment\n",
            "User-friendly interface\n",
            "\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "âœ¨ PROJECT PROGRESSING EXCELLENTLY! âœ¨\n",
            "\n",
            "\n",
            "All phases complete with REAL data:\n",
            "âœ… Phase 1 (Days 2-7):   Data pipeline (Your examples)\n",
            "âœ… Phase 2 (Days 8-10):  Baseline model (Tested on your data)\n",
            "âœ… Phase 3 (Days 13-16): T5 training (Trained on your pairs)\n",
            "âœ… Day 17:               Evaluation (Results on YOUR Google Sheet)\n",
            "\n",
            "\n",
            "Ready for deployment! ðŸš€\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "âœ… Summary saved: /content/drive/MyDrive/ClearSpeak/data/examples/day17_summary.txt\n",
            "\n",
            "ðŸŽ‰ READY FOR NEXT PHASE (DAYS 18-21)!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rOQTs44yBV87"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}